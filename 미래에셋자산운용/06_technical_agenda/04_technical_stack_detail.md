# 04. 핵심 기술 스택 상세: Apache Airflow

미래에셋자산운용 Platform Engineering 팀의 데이터 파이프라인 아키텍처에서 핵심적인 역할을 수행하는 **Apache Airflow**에 대해 정리한 문서입니다. 면접 시 "Airflow가 무엇이며 왜 사용하는가?"라는 질문에 대응할 수 있도록 구성되었습니다.

---

## 1. Apache Airflow란?

Apache Airflow는 복잡한 **워크플로우(Workflow)**를 작성, 예약 및 모니터링하기 위한 오픈소스 플랫폼입니다. 파이썬(Python) 코드로 워크플로우를 정의하며, 데이터 파이프라인의 **오케스트레이터(Orchestrator)** 역할을 합니다.

### 💡 핵심 개념: DAG (Directed Acyclic Graph)
- **DAG(유향 비순환 그래프)**: Airflow에서 워크플로우를 정의하는 방식입니다.
- 여러 태스크(Task)들이 화살표로 연결되어 순서와 의존성을 가지지만, 순환(Loop)하지 않는 구조를 의미합니다.
- 예: `시장 데이터 수집` -> `데이터 정제` -> `DB 적재` -> `백테스팅 실행`

---

## 2. 왜 자산운용사에서 Airflow를 사용하는가?

자산운용사의 데이터 플랫폼은 **정확성**과 **적시성**이 생명입니다. Airflow는 이를 위해 다음과 같은 강점을 제공합니다.

1. **파이썬 기반의 유연함**:
   - 퀀트 전략이나 AI 모델이 대부분 파이썬으로 작성되므로, 이를 그대로 파이프라인 태스크로 통합하기 매우 유리합니다.
2. **복잡한 의존성 관리**:
   - 예를 들어, '미국 시장 종가'와 '한국 시장 종가'가 모두 수집된 후에만 실행되어야 하는 '글로벌 포트폴리오 분석' 태스크의 선후 관계를 완벽하게 제어할 수 있습니다.
3. **실패 복구 및 재시도 (Retry)**:
   - 외부 API(시장 데이터 제공처)의 일시적 장애로 수집이 실패했을 때, 자동으로 일정 시간 후 재시도하도록 설정할 수 있어 운영 공수를 줄여줍니다.
4. **강력한 모니터링 UI**:
   - 수백 개의 파이프라인 중 어떤 단계에서 문제가 생겼는지 시각적으로 즉시 파악하고 대응할 수 있습니다.

---

## 3. 면접용 답변 가이드

**Q: Airflow가 무엇이고, 우리 팀에서 어떤 역할을 할 것이라고 생각하나요?**

> **A:** "Airflow는 파이썬 코드로 데이터 워크플로우를 설계하고 관리하는 오케스트레이션 도구입니다. 미래에셋자산운용의 Platform Engineering 팀에서는 **글로벌 시장 데이터를 안정적으로 수집하고 처리하는 파이프라인의 관리자 역할**을 할 것이라고 생각합니다. 
> 
> 특히, 수많은 종목의 데이터를 수집할 때 발생하는 의존성 문제를 DAG로 명확히 관리하고, 장애 발생 시 자동 재시도 기능을 통해 데이터 누락 없는 안정적인 플랫폼 운영을 가능하게 하는 핵심 도구라고 이해하고 있습니다."

---

## 4. 기존 기술 스택과의 조화 (Candidate Fit)

- **Python**: Airflow는 Python 기반이므로, 후보자의 높은 Python 숙련도는 DAG 작성 및 Custom Operator 개발에 즉시 활용 가능합니다.
- **Kubernetes**: 시스템 아키텍처에서 보셨듯이, Airflow를 KubernetesExecutor와 함께 사용하면 각 태스크를 독립된 Pod로 실행하여 자원을 효율적으로 관리하고 확장성을 확보할 수 있습니다.
- **금융 데이터 정합성**: 후보자가 강조한 '숫자에 대한 신뢰'를 지키기 위해, Airflow의 센서(Sensor) 기능을 활용하여 데이터가 완전히 적재되었는지 확인 후 다음 연산을 수행하는 구조를 설계할 수 있습니다.

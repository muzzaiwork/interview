# 02. 직무의 큰 그림 및 시스템 아키텍처 개요

미래에셋자산운용 Platform Engineering 팀의 Backend Engineer로서 마주하게 될 **전체 시스템의 구조(Big Picture)**와 그 안에서 **나의 구체적인 역할**을 정의합니다.

---

## 🌐 직무의 큰 그림: 글로벌 AI/퀀트 자산운용 플랫폼

본 직무의 핵심은 전 세계에서 발생하는 방대한 금융 데이터를 수집하여, AI 모델과 퀀트 전략이 심리스(Seamless)하게 구동되고 그 결과가 글로벌 지사에 안정적으로 서빙되는 **엔드투엔드(E2E) 플랫폼**을 구축하는 것입니다.

### 부하에 따른 단계별 확장 시나리오 (Scalability Roadmap)

데이터량과 연산 부하가 증가함에 따라 시스템이 어떻게 쿠버네티스를 통해 확장되는지 단계별로 정의합니다.

#### [Step 1] 초기 단계: 단일 워커 및 수동 관리
- **상황**: 수집 대상 종목 수가 적고 연산 복잡도가 낮음.
- **구조**: 단일 Pod 내에서 순차적으로 데이터 수집 및 정제 수행.

#### [Step 2] 확장 단계: 분산 처리 엔진 도입 (Horizontal Scaling)
- **상황**: 글로벌 데이터(미국, 유럽 등) 추가로 수집량 급증, 백테스팅 요청 증가.
- **구조**: **Airflow KubernetesPodOperator**를 활용하여 수집/정제 작업을 수십 개의 Pod로 분산.
```mermaid
graph LR
    subgraph "K8s Cluster"
        AF[Airflow Scheduler] --> |Task 배분| P1[Worker Pod 1: 한국]
        AF --> |Task 배분| P2[Worker Pod 2: 미국]
        AF --> |Task 배분| P3[Worker Pod 3: 유럽]
        P1 & P2 & P3 --> S3[(공유 저장소: S3)]
    end
```

#### [Step 3] 고도화 단계: 부하 기반 지능형 자동 확장 (Auto-scaling)
- **상황**: 장 마감 직후 데이터 폭주, 수천 명의 매니저가 동시 백테스팅 수행.
- **구조**: **HPA(Pod 확장)**와 **CA(Node 확장)**가 연동되어 인프라가 유동적으로 팽창/수축.
```mermaid
graph TD
    subgraph "지능형 인프라 레이어"
        Metric[부하 감지: CPU/Memory/Queue] --> |Scale Out| HPA[HPA: Pod 개수 증설]
        HPA --> |Resource 부족| CA[Cluster Autoscaler: 물리 노드 추가]
        
        subgraph "확장된 컴퓨팅 자원"
            W1[Quant Pod]
            W2[Quant Pod]
            Wn[Quant Pod...]
        end
    end
    
    W1 & W2 & Wn --> |병렬 처리| Result[대규모 연산 완료]
```

---

### 🔄 전체 데이터 라이프사이클 (End-to-End Workflow)

수집된 데이터가 가공을 거쳐 백테스팅 엔진에서 결과로 산출되기까지의 전 과정입니다.

```mermaid
sequenceDiagram
    participant S as 데이터 소스 (시장/재무)
    participant P as 파이프라인 (수집/가공)
    participant ST as 저장소 (S3/DB)
    participant E as 백테스팅 엔진 (연산)
    participant U as 사용자 (매니저/지사)

    Note over S, P: 1. 데이터 수집 (Ingestion)
    S->>P: Raw Data (API/FTP)
    
    Note over P: 2. 데이터 가공 (Preprocessing)
    P->>P: 결측치 처리 & 포맷 표준화
    P->>P: 시점 정렬 (Point-in-Time)
    P->>ST: 가공 데이터 저장 (Parquet/SQL)

    Note over U, E: 3. 백테스팅 요청
    U->>E: 전략 파라미터 입력
    ST->>E: 가공 데이터 주입
    
    Note over E: 4. 전략 시뮬레이션
    E->>E: 벡터화 행렬 연산
    E->>E: 성과 지표 산출 (CAGR, MDD)
    
    Note over E, U: 5. 결과 서빙
    E->>U: 최종 리포트 및 시각화 제공
```

| 단계 | 핵심 엔지니어링 포인트 | 비고 |
| :--- | :--- | :--- |
| **수집** | 분산 스케줄링 (Airflow), 결함 허용 (Retry) | 가용성 확보 |
| **가공** | **시점 정렬(PIT)**, 데이터 정합성 검증 | 신뢰도 확보 |
| **백테스팅** | **벡터화 연산(Pandas/NumPy)**, 분산 컴퓨팅 | 성능 최적화 |
| **서빙** | 저지연 API (FastAPI), 캐싱 (Redis) | 사용자 경험 |

---

## 🎯 포지션의 역할: "플랫폼의 혈관을 설계하고 관리하는 엔지니어"

아키텍처 상에서 Backend Engineer인 저의 역할은 단순히 코드를 짜는 것을 넘어, **데이터의 흐름(Blood flow)을 설계하고 플랫폼의 안정성(Stability)을 책임지는 것**입니다.

### 1. 데이터 파이프라인 마스터 (Layer 1)
- **역할**: 방대한 로우 데이터를 '신뢰할 수 있는 데이터'로 변환하는 자동화 파이프라인 구축.
- **기여**: Airflow를 통한 워크플로우 관리와 데이터 무결성 검증 로직 구현을 통해 연산 엔진에 깨끗한 연료를 공급합니다.

### 2. 고성능 연산 인프라 최적화 (Layer 2)
- **역할**: 수만 건의 전략 시뮬레이션이 병목 없이 돌아가도록 연산 자원을 오케스트레이션.
- **기여**: Kubernetes Job을 활용한 분산 처리와 벡터화 연산 최적화를 통해 백테스팅 시간을 단축시킵니다.

### 3. 견고한 API 아키텍처 및 서빙 (Layer 3)
- **역할**: 연산 결과와 AI 모델을 전 세계 어디서든 저지연(Low-latency)으로 호출할 수 있는 인터페이스 구축.
- **기여**: FastAPI 기반의 비동기 서빙 구조와 클라우드 네이티브 인프라 관리를 통해 서비스 가용성을 보장합니다. (상세 활용 방식은 **[쿠버네티스 상세 활용](./11_kubernetes_deep_dive.md)** 참고)

---

## 🚀 기술적 도전 과제 및 나의 강점 매칭

| 기술적 아젠다 | 상세 내용 | 나의 강점 (Fit) |
| :--- | :--- | :--- |
| **데이터 정합성** | 금융 데이터의 시점 정렬 및 무결성 확보 | 21억 건의 데이터 리팩토링 및 대사 시스템 구축 경험 |
| **시스템 확장성** | 글로벌 사용량 증가에 따른 유연한 인프라 확장 | SVN에서 Git/Jenkins 이관 및 K8s 기반 현대화 경험 |
| **복잡도 관리** | 수많은 금융 상품과 전략 로직의 모듈화 | Strategy/Factory 패턴을 통한 80+ 로직 개선 경험 |

---

## 💡 면접용 핵심 요약 멘트

> "제가 이해한 미래에셋자산운용의 플랫폼은 **글로벌 금융 데이터를 연산 자산으로 전환하는 거대한 엔진**입니다. 저는 이 엔진의 각 부품인 파이프라인, 연산 노드, 서빙 API를 유기적으로 연결하고, 특히 **데이터의 정합성과 인프라의 확장성**이라는 두 마리 토끼를 잡는 백엔드 전문가로서 기여하고 싶습니다. 21억 건의 데이터를 다루며 숫자에 대한 신뢰를 지켜온 저의 경험은, 퀀트/AI 플랫폼의 안정성을 확보하는 데 가장 강력한 무기가 될 것입니다."
